% vim: spl=en_us
\section{Orthogonality}
The inner product in pre-Hilbert spaces allows for a notion of \emph{orthogonality} of two vectors.
\begin{definition}{Orthogonality}{orthogonality}
    Let \((X, \inner{\noarg}{\noarg})\) be a pre-Hilbert space. A vector \(x \in X\) is \emph{orthogonal} to a vector \(y \in X\) if \(\inner{x}{y} = 0\). The \emph{orthogonal complement} of a subset \(Y \subset X\) is the set
    \begin{equation*}
        Y^\perp = \setc{x \in X}{\forall y \in Y : \inner{y}{x} = 0},
    \end{equation*}
    that is, every vector in \(Y^\perp\) is orthogonal to all vectors in \(Y\).
\end{definition}
\begin{remark}
    It should be clear from the definition of an inner product that if \(x\) is orthogonal to \(y\), then \(y\) is orthogonal to \(x\). Moreover, we have \(x\) orthogonal to \(x\) if and only if \(x = 0\), that is, \(Y \cap Y^\perp = \set{0}\).
\end{remark}

\begin{proposition}{Orthogonal complement is a closed subspace}{orthogonal_closed}
    Let \((X, \inner{\noarg}{\noarg})\) be a pre-Hilbert space. If \(Y \subset X\) is a subset, then its orthogonal complement \(Y^\perp\) is a closed linear subspace.
\end{proposition}
\begin{proof}
    Clearly, the zero vector belongs to the orthogonal complement. Let \(u, v \in Y^\perp\) and let \(\alpha \in \mathbb{C}\), then for all \(y \in Y\), we have
    \begin{equation*}
        \inner{y}{u + \alpha v} = \inner{y}{u} + \alpha\inner{y}{v}
    \end{equation*}
    by linearity. Hence, \(\inner{y}{u + \alpha v} = 0\) for all \(y \in Y\), that is, \(Y^\perp\) is a linear subspace.

    Let \(\family{x_n}{n\in \mathbb{N}} \subset Y^\perp\) be a convergent sequence to some \(x \in X\), then by the continuity of the inner product we have
    \begin{equation*}
        \inner{y}{x} = \inner*{y}{\lim_{n\to\infty} x_n} = \lim_{n\to\infty} \inner{y}{x_n} = 0
    \end{equation*}
    for all \(y \in Y\). That is, \(x \in Y^\perp\), so \(Y^\perp\) must be closed.
\end{proof}

We now use the best approximation theorem to show every vector in a Hilbert space has a unique decomposition in a closed subspace and its orthogonal complement.
\begin{theorem}{Orthogonal decomposition}{orthogonal_decomposition}
    Let \(M\) be a closed linear subspace of a Hilbert space \(\hilbert\). Then, every \(x \in \hilbert\) admits a unique decomposition \(x = x_\parallel + x_\perp,\) where \(x_\parallel \in M\) and \(x_\perp \in M^\perp\). Moreover, \(x_\parallel\) is the best approximation of \(x\) in \(M\).
\end{theorem}
\begin{proof}
    Since every closed subspace of a Hilbert space is in particular a closed convex subset, it admits a unique best approximation for every vector in the Hilbert space, by \cref{thm:best_approximation}. For every \(x \in \hilbert\) there exists a unique \(x_\parallel \in M\) such that
    \begin{equation*}
        \norm{x_\parallel - x} = \inf_{y \in M}{\norm{y - x}}.
    \end{equation*}

    Notice for every \(y \in M\) and \(\lambda \in \mathbb{C}\) we have \(x_\parallel + \lambda y \in M\), then
    \begin{equation*}
        \norm{x - x_\parallel}^2 \leq \norm{x - x_\parallel - \lambda y}^2,
    \end{equation*}
    with equality being equivalent to the case \(y = 0\). Let \(x_\perp = x - x_\parallel\), then
    \begin{equation*}
        \norm{x_\perp}^2 \leq \norm{x_\perp}^2 + \abs{\lambda}^2\norm{y}^2 - 2 \Re(\inner{x_\perp}{\lambda y}),
    \end{equation*}
    which yields
    \begin{equation*}
        2 \Re(\inner{x_\perp}{\lambda y}) \leq  \abs{\lambda}^2 \norm{y}^2,
    \end{equation*}
    for all \(y \in M\) and all \(\lambda \in \mathbb{C}\). Let \(\theta \in [0, 2\pi)\) be such that \(\inner{x_\perp}{y} = \abs*{\inner{x_\perp}{y}}e^{i\theta}\) and consider \(\lambda = r e^{-i\theta}\) with \(r > 0\), then \(\Re(\inner{x_\perp}{\lambda y}) = r\abs*{\inner{x_\perp}{y}}\) for all \(y \in M\). This yields
    \begin{equation*}
        \abs*{\inner{x_\perp}{y}} \leq \frac12 r \norm{y}^2
    \end{equation*}
    for all \(r > 0\) and all \(y \in M\), which can only hold if \(\inner{x_\perp}{y} = 0\). We have thus shown \(x_\perp \in M^\perp\).

    Suppose there exists \(\xi_\parallel \in M\) and \(\xi_\perp \in M^\perp\) such that \(x = \xi_\parallel + \xi_\perp\). Then, it must hold that
    \begin{equation*}
        \xi_\parallel - x_\parallel = x_\perp - \xi_\perp.
    \end{equation*}
    Notice \(\xi_\parallel - x_\parallel \in M\) and \(x_\perp - \xi_\perp \in M^\perp\), since \(M\) and \(M^\perp\) are linear subspaces, hence \(\xi_\parallel - x_\parallel \in M \cap M^\perp\). That is, \(\xi_\parallel - x_\parallel = 0\), so \(\xi_\parallel = x_\parallel\) and \(\xi_\perp = x_\perp\), showing uniqueness.
\end{proof}

We now show the relation between the closure of a linear subspace with orthogonal complements. First we prove two lemmas.
\begin{lemma}{Orthogonal complement and inclusion partial order}{complement_subsets}
    Let \(X\) be a pre-Hilbert space. Then if \(A \subset B \subset X\), we have \(B^\perp \subset A^\perp\).
\end{lemma}
\begin{proof}
    Let \(x \in B^\perp\), then \(\inner{y}{x} = 0\) for all \(y \in B\). In particular, \(\inner{y}{x}\) for all \(y \in A \subset B\), then \(x \in A^\perp\).
\end{proof}

\begin{lemma}{Closure of a linear subspace is a linear subspace}{closure_subspace}
    Let \(M\) be a linear subspace of a pre-Hilbert space. Then \(\cl{M}\) is a linear subspace.
\end{lemma}
\begin{proof}
    Recall \(\xi \in \cl{M}\) if and only if there exists a convergent sequence of elements in \(M\) that converges to \(\xi\), by \cref{lem:convergent_closure}.

    Since \(M\) is a linear subspace, \(0 \in M\), then with the constant sequence \(\family{0}{n\in \mathbb{N}} \subset M\) we have \(0 \in \cl{M}\). Let \(x, y \in \cl{M}\), then there exist sequences \(\family{x_n}{n\in \mathbb{N}}, \family{y_n}{n\in \mathbb{N}} \subset M\) that converge to \(x\) and \(y\). Since \(M\) is a linear subspace, for all \(\alpha \in \mathbb{C}\) we have \(x_n + \alpha y_n \in M\) for all \(n \in \mathbb{N}\). By the continuity of vector addition and scalar multiplication, it follows that \(x_n + \alpha y_n \to x + \alpha y\), that is, there exists a convergent sequence \(\family{x_n + \alpha y_n}{n \in \mathbb{N}}\subset M\) that converges to \(x + \alpha y\). We have thus shown that \(x + \alpha y\) is a point of closure of \(M\), that is, \(x + \alpha y \in \cl{M}\) for all \(x, y \in \cl{M}\) and all \(\alpha \in \mathbb{C}\).
\end{proof}

\begin{theorem}{Closure and orthogonal complement}{closure_perp}
    Let \(M\) be a linear subspace of a Hilbert space \(\hilbert\). Then \(\cl{M} = (M^\perp)^\perp\).
\end{theorem}
\begin{proof}
    Let \(x \in M\) and let \(y \in M^\perp\). Then \(x\) is perpendicular to \(y\), that is, \(x \in (M^\perp)^\perp\). This shows \(M \subset (M^\perp)^\perp\), hence \(\cl M \subset (M^\perp)^\perp\) since the orthogonal complement is closed and the closure \(\cl{M}\) is the smallest closed set containing \(M\).

    Let \(x \in (M^\perp)^\perp\). By \cref{lem:closure_subspace}, \(\cl{M}\) is a closed linear subspace, then for all \(y \in \hilbert\) there exist unique \(y_\parallel \in \cl{M}\) and \(y_\perp \in (\cl{M})^\perp\) such that \(y = y_\parallel + y_\perp\) by \cref{thm:orthogonal_decomposition}. In particular, we consider the orthogonal decomposition \(x = x_\parallel + x_\perp\) and we claim \(x_\perp = 0\). For all \(y \in \hilbert\), we have
    \begin{equation*}
        \inner{x_\perp}{y} = \inner{x_\perp}{y_\perp} = \inner{x - x_\parallel}{y_\perp} = \inner{x}{y_\perp},
    \end{equation*}
    since \(\inner{x_\parallel}{y_\perp} = \inner{x_\perp}{y_\parallel} = 0\). By \cref{lem:complement_subsets}, \(M \subset \cl{M}\) yields \((\cl{M})^\perp \subset M^\perp\), that is, \(y_\perp \in M^\perp\) for all \(y \in \hilbert\), then \(\inner{x}{y_\perp} = 0\). We have thus shown \(\inner{x_\perp}{y} = 0\) for all \(y \in \hilbert\), and it follows from non-degeneracy of the inner product that \(x_\perp = 0\) as claimed. That is, \(x = x_\parallel \in \cl{M}\), hence \((M^\perp)^\perp \subset \cl{M}\).
\end{proof}

Before illustrating the previous result with a concrete example, we relate linear independence with orthogonality and, for the sake of completeness, recall the definition of a Hamel basis for the sake of completeness.

\begin{lemma}{Linear independence and orthogonality}{linear_independent_orthogonal}
    Let \((V, \inner{\noarg}{\noarg})\) be a pre-Hilbert space. Let \(F\) be a non-empty orthogonal subset of \(V\), that is, \(0 \notin F\) and for all \(u,v \in F\) we have \(\inner{u}{v} = 0\) if \(u \neq v\). Then, \(F\) is linearly independent.
\end{lemma}
\begin{proof}
    Let \(S\) be a non-empty finite subset of \(F\) with \(n\) elements. Then, we may enumerate \(S\) as the finite family \(\ffamily{v_i}{i=1}{n} = S\). We consider a finite family \(\ffamily{\alpha_i}{i=1}{n}\) of \(n\) complex numbers such that
    \begin{equation*}
        \sum_{i =1}^n \alpha_i v_i = 0.
    \end{equation*}
    For every \(j \in \set{1,2,\dots, n}\), we may take the inner product of the above expression with the element \(v_j\), yielding \(\alpha_j \norm{v_j}^2 = 0\) for all \(j\), since \(\inner{v_j}{\alpha_i v_i} = \alpha_i \norm{v_i}^2 \delta_{ij}\). Since \(0 \notin F\), we have \(\alpha_i = 0\), for all \(i \in \set{1,2,\dots, n}\). Hence, \(F\) is linearly independent.
\end{proof}

\begin{definition}{Linear span}{linear_span}
    Let \(V\) be a linear space and let \(F \subset V\) be a non-empty subset. The \emph{linear span \(\lspan{F}\) of \(F\)} is the set
    \begin{equation*}
        \lspan{F} = \setc*{\sum_{i = 1}^n \lambda_i v_i}{n \in \mathbb{N}, \ffamily{\lambda_i}{i=1}{n} \subset \mathbb{C}, \ffamily{v_i}{i=1}{n}\subset F}
    \end{equation*}
    consisting of all finite linear combinations of elements in \(F\). The set \(F\) is called a \emph{generating set} for \(\lspan{F}\).
\end{definition}
\begin{remark}
    We check \(\lspan F\) is a linear subspace of \(V\). Clearly, \(0 \in \lspan F\). Let \(x, y \in \lspan F\), then \(x = \sum_{i = 1}^{n} \lambda_i x_i\) and \(y = \sum_{j = 1}^{m} \mu_j y_j\) where \(\ffamily{\lambda_i}{i=1}{n}, \ffamily{\mu_j}{j = 1}{m} \subset \mathbb{C}\) and \(\ffamily{x_i}{i=1}{n}, \ffamily{y_j}{j=1}{m} \subset F\) for natural numbers \(n,m \geq 1\). Let \(\alpha \in \mathbb{C}\), then setting \(\eta_k = \lambda_k\), \(v_k = x_k\) for \(k \in \set{1, 2, \dots, n}\) and \(\eta_{k} = \alpha \mu_{k-n}\), \(v_{k} = y_{k-n}\) for \(k \in \set{n+1, n+2, \dots, n+m}\), yields \(x + \alpha y = \sum_{k = 1}^{m+n} \eta_k v_k\), that is \(x + \alpha y \in \lspan F\).
\end{remark}

\begin{proposition}{Linear span of a subset is the smallest linear subspace that contains it}{linear_span_smallest}
    Let \(F \subset V\) be a non-empty subset of a linear space \(V\). If \(E\) is a subset of \(V\) that contains \(F\), then \(\lspan{F} \subset \lspan{E}\). Moreover, if \(E\) is a linear subspace of \(F\), we have \(\lspan{F} \subset E\).
\end{proposition}
\begin{proof}
    Let \(v \in \lspan{F}\). Then \(v\) is a linear combination of elements in \(F\). Since \(F \subset E\), every element in \(F\) is a member of \(E\), that is, \(v\) is a linear combination of vectors in \(E\). Hence, \(v \in \lspan{E}\), then \(\lspan{F} \subset \lspan{E}\). If, in addition, \(E\) is a linear subspace, then \(\lspan{E} = E\), since linear subspaces are closed under linear combinations.
\end{proof}

\begin{definition}{Hamel basis and dimension}{hamel_basis}
    Let \(V\) be a linear space. A \emph{Hamel basis} is a non-empty subset \(F\subset V\) that is linearly independent and a generating set for \(V\). If \(F\) is finite, we say \(V\) is finite dimensional with \emph{dimension} equal to the number of elements in \(F\), otherwise we say \(V\) is infinite dimensional.
\end{definition}
\begin{remark}
    Using Zorn's lemma, it can be shown that every non-trivial vector space (in fact, every non-trivial module over a division ring) admits a Hamel basis. This result is assumed without proof.
\end{remark}
\begin{remark}
    Rigorously it would be necessary to show well-definition of dimension, which we will simply assume for brevity.
\end{remark}

\begin{example}{Dense set in \(\ell_2\)}{dense_l2}
    Let \(\ell_2\) be the Hilbert space of square-summable sequences and let \(\mathfrak{d} \subset \ell_2\) be the set of all sequences with a finite number of non-zero components. Then, \(\mathfrak{d}\) is infinite-dimensional, \((\mathfrak{d}^\perp)^\perp = \ell_2\) and \(\mathfrak{d}\) is dense in \(\ell_2\).
\end{example}
\begin{proof}
    Recall the inner product in \(\ell_2\) is defined as \(\inner{a}{b} = \sum_{n = 1}^\infty \conj{a_n} b_n\), for two sequences \(a = \family{a_n}{n\in \mathbb{N}}\) and \(b = \family{b_n}{n \in \mathbb{N}}\). We show the set \(E = \family{e_i}{n\in \mathbb{N}}\), where \(e_i\) is the sequence defined by
    \begin{align*}
        e_i : \mathbb{N} &\to \mathbb{C}\\
                       j &\mapsto \delta_{ij}
    \end{align*}
    is a Hamel basis for \(\mathfrak{d}\). Clearly, each sequence \(e_i\) is square-summable and each sequence has a finite number of non-zero components, then \(e_i \in \mathfrak{d} \subset \ell_2\), for all \(i \in \mathbb{N}\). Notice \(E\) is an orthogonal set, since for all \(i,j \in \mathbb{N}\) we have
    \begin{equation*}
        \inner{e_i}{e_j} = \sum_{n = 1}^\infty \delta_{in} \delta_{jn} = \delta_{ij},
    \end{equation*}
    then \(E\) is linearly independent by \cref{lem:linear_independent_orthogonal}. Since \(E \subset \mathfrak{d}\) and \(\mathfrak{d}\) is a linear subspace of \(\ell_2\), then \(\lspan{E} \subset \mathfrak{d}\). Let \(s \in \mathfrak{d}\), then there is a maximal finite set \(J \subset \mathbb{N}\) such that \(s(\mathbb{N} \setminus J) = \set{0}\), and as a result, we have
    \begin{equation*}
        s = \sum_{j \in J} s(j) e_j,
    \end{equation*}
    hence \(\mathfrak{d} \subset \lspan{E}\). We have thus shown \(E\) is a Hamel basis for \(\mathfrak{d}\).

    Let \(x = \family{x_n}{n\in \mathbb{N}} \in \mathfrak{d}^\perp\). Notice for all \(i \in \mathbb{N}\), we have \(\inner{e_i}{x} = x_i\). Then, \(x_i = 0\) for all \(i \in \mathbb{N}\), that is, \(x\) is the zero vector. We have shown \(\mathfrak{d}^\perp = \set{0}\). Since every vector is orthogonal to the zero vector by non-degeneracy, we have \((\mathfrak{d}^\perp)^\perp = \ell_2\). Finally, it follows from \cref{thm:closure_perp} that \(\cl\mathfrak{d} = \ell_2\), that is, \(\mathfrak{d}\) is dense in \(\ell_2\).
\end{proof}


